<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>CPU Performance: Intel's Own Claims | JazzVlog</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="Before we get into the new AI benchmarks, let’s take a quick look at the usual CPU benchmarks and performance claims made available by Intel. 

For this comparison we’ll focus on the second row – the first row is comparing the insanely priced 400W dual-die Intel Platinum 9282 to a much more reasonable and available to everyone Intel Platinum 8180. The second row tells it all: a few MHz and slightly higher RAM speeds result in a 3% (Integer) to 5% (FP) performance increase compared to the first-generation Xeon Scalable parts."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>JazzVlog</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>CPU Performance: Intel's Own Claims</h1><div><strong>Publish date: </strong>2024-08-20</div><p>Before we get into the new AI benchmarks, let’s take a quick look at the usual CPU benchmarks and performance claims made available by Intel.&nbsp;</p><p><a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/14466/Intelperf1_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>For this comparison we’ll focus on the second row – the first row is comparing the insanely priced <span data-scayt-word=400W data-wsc-lang=en_US>400W</span> dual-die Intel Platinum&nbsp;9282 to a much more reasonable and available to everyone Intel Platinum 8180. The second row tells it all: a few MHz and slightly higher RAM speeds result in a 3% (Integer) to 5% (FP) performance increase compared to the first-generation <span data-scayt-word=Xeon data-wsc-lang=en_US>Xeon</span> Scalable parts. The higher boost in floating point performance is probably the result of the fact that Intel's second generation parts can use&nbsp;faster <span data-scayt-word=DDR4-2933 data-wsc-lang=en_US>DDR4-2933</span> <span data-scayt-word=DIMMs data-wsc-lang=en_US>DIMMs</span> and hence offer more bandwidth to the cores.&nbsp;</p><p>The midrange <span data-scayt-word=SKUs data-wsc-lang=en_US>SKUs</span> get a bigger boost as some of <span data-scayt-word=x2xx data-wsc-lang=en_US>x2xx</span> <span data-scayt-word=Xeons data-wsc-lang=en_US>Xeon</span>&nbsp;Scalable&nbsp;parts get more cores and more <span data-scayt-word=L3-cache data-wsc-lang=en_US>L3 cache</span> than the previous <span data-scayt-word=x1xx data-wsc-lang=en_US>x1xx</span> parts. For example, the 6252 has 24 cores and 35.75 MB L3, while the 6152 had 22 cores and 30.25 MB L3.&nbsp;</p><p>&nbsp;<a href=#><img alt src=https://cdn.statically.io/img/images.anandtech.com/doci/14466/Intelperf2_575px.png style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p>The comparison with AMD's EPYC 7601 however deserves our attention, as there’s some interesting data here. Again, the comparison of a 400W, $50k chiplet CPU with a 180W $4k one does not make any sense whatsoever, so we ignore the first line.&nbsp;</p><p>The Linpack numbers are not surprising: the more expensive&nbsp;Skylake SKUs add a 512-bit FMAC to the already existing dual 256-bit FMACs, offering up to 4 times more AVX throughput than AMD's EPYC. AMD's next generation will be a lot more competitive in this area as the each FP unit is <a href=#>now capable </a>of doing 256-bit AVX&nbsp;instead of 128-bit.&nbsp;</p><p>The image classification results clearly show that Intel is trying to convince people that some AI applications should simply run on a CPU, no GPU needed. Well, at least for now…&nbsp;</p><p>The fact that Intel claims that database performance is a lot better than on the EPYC is quite interesting, as we’ve previously pointed out that AMD's four NUMA dies on a chip does have drawbacks. Quoting our <a href=#>Xeon Skylake vs EPYC review</a>:&nbsp;</p><p>Out of the box, the EPYC CPU is a rather mediocre transactional database CPU ...&nbsp;transactional databases will remain Intel territory for now.</p><p>In databases, cache (coherency) latency plays an important role.&nbsp;It will be interesting to see how well AMD has addressed this weakness in the second generation EPYC server chips.&nbsp;</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH51gJVvZqKmpJq5bsTEqKVmm5GosKKwxGajmqOVYsO0ec2voJ2hkWLBtr7Ip55ocA%3D%3D</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>